{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74975ac3",
   "metadata": {},
   "source": [
    "#### NLP | MVP\n",
    "\n",
    "# Coronavirus Tweets: Spring 2020<a id='top'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea017a0f",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "## **Analysis Goal**  \n",
    "The client, [name](link), ...\n",
    "wants to ... and \n",
    "requested a model to find a pattern ... in tweets in April. \n",
    "\n",
    "Impetus?\n",
    "\n",
    "**RQ:** ....?\n",
    "\n",
    "## **Process**\n",
    "**Data source:** \n",
    "Coronavirus COVID-19 Tweets [early](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-early-april) and [late](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-late-april) April\n",
    "\n",
    "\n",
    "**Models:** \n",
    "* [name] model, fit a [model name](#??):\n",
    "    * eval metric\n",
    "* [name] model, fit a [model name](#??):\n",
    "    * eval metric\n",
    "\n",
    "\n",
    "## **Preliminary Visualizations**\n",
    "[Figure 1. Name](#??)<br/>\n",
    "[Figure 1. Name](#??)<br/>\n",
    "\n",
    "## **Preliminary Conclusions**\n",
    "The [name] model ... showed....<br/>\n",
    "\n",
    "The next step .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64179b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import string\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38894c8",
   "metadata": {},
   "source": [
    "## 1 | Dataset: Coronavirus Tweets ([early](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-early-april) and [late](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-late-april) April) <a id='1'></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83cc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import one csv file to see data\n",
    "# single_df = pd.read_csv('20200401.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the following 7 columns on full data import \n",
    "\n",
    "#  2   created_at            591480 non-null  object \n",
    "#  3   screen_name           591480 non-null  object \n",
    "#  4   text                  591480 non-null  object \n",
    "#  13  country_code          26040 non-null   object \n",
    "#  18  account_lang          0 non-null       float64\n",
    "#  20  verified              591480 non-null  bool   \n",
    "#  21  lang                  591480 non-null  object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read list of April 2020 files, while ommitting columns above\n",
    "\n",
    "# path = r'/Users/sandraparedes/Documents/GitHub/metis_dsml/05_nlp/g00-nlp-project/data' \n",
    "# all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# li = []\n",
    "\n",
    "# for filename in all_files:\n",
    "#     df = pd.read_csv(filename, index_col=None, header=0, usecols=[2,3,4,13,18,20,21])\n",
    "#     li.append(df)\n",
    "# df = pd.concat(li, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678fce99",
   "metadata": {},
   "source": [
    "## 2 | Exploratory Data Analysis<a id='2'></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['country_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['lang'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454cdc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('English entries:', (df[df[\"lang\"] == 'en'].count())['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('US entries:', (df[df[\"country_code\"] == 'US'].count())['country_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eng_us_df = df[(df['country_code'] == 'US') &\n",
    "#                (df['lang'] == 'en')]\n",
    "# eng_us_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eng_us_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908cc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eng_us_df['text'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d83d4",
   "metadata": {},
   "source": [
    "### English + US df: 138,789 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b578af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save cleaned df as tweet_df\n",
    "\n",
    "# tweet_df = eng_us_df \n",
    "# tweet_df.to_pickle('coronavirus_tweets_df.pkl')\n",
    "# tweet_df.to_csv(r'//Users/sandraparedes/Documents/GitHub/metis_dsml/05_nlp/g00-nlp-project/data/coronavirus_tweets_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233740c",
   "metadata": {},
   "source": [
    "### 2a | [start here with nlp](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g1-nlp-overview/NLP_Supervised_Learning.ipynb)<a id='2a'></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61163bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read df in\n",
    "df = pd.read_csv('coronavirus_tweets_df.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa418593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>country_code</th>\n",
       "      <th>account_lang</th>\n",
       "      <th>verified</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-06T00:00:05Z</td>\n",
       "      <td>WFMGINC</td>\n",
       "      <td>....#SUNDAYFUNDAY #coronavirus style #vino cheers üç∑ https://t.co/SrymChBkq2</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-06T00:00:14Z</td>\n",
       "      <td>jpomietlasz</td>\n",
       "      <td>This pandemic has confirmed my worst fears, most people don‚Äôt know how to make entertaining videos. #Covid_19 #SinceIveBeenQuarantined #AmericasUnfunniestVideos #WrestleMania #tonyaharding</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at  screen_name  \\\n",
       "0  2020-04-06T00:00:05Z      WFMGINC   \n",
       "1  2020-04-06T00:00:14Z  jpomietlasz   \n",
       "\n",
       "                                                                                                                                                                                           text  \\\n",
       "0                                                                                                                   ....#SUNDAYFUNDAY #coronavirus style #vino cheers üç∑ https://t.co/SrymChBkq2   \n",
       "1  This pandemic has confirmed my worst fears, most people don‚Äôt know how to make entertaining videos. #Covid_19 #SinceIveBeenQuarantined #AmericasUnfunniestVideos #WrestleMania #tonyaharding   \n",
       "\n",
       "  country_code account_lang verified lang  \n",
       "0           US          NaN    False   en  \n",
       "1           US          NaN    False   en  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bdb5a4",
   "metadata": {},
   "source": [
    "### Remove numbers, capital letters, and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6219ab77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                            sundayfunday  coronavirus style  vino cheers üç∑ https   t co  \n",
       "1    this pandemic has confirmed my worst fears  most people don‚Äôt know how to make entertaining videos      sinceivebeenquarantined  americasunfunniestvideos  wrestlemania  tonyaharding\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*',' ', str(x))\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "df['text'] = df.text.map(alphanumeric).map(punc_lower)\n",
    "# df.head(2)\n",
    "\n",
    "text = df.text\n",
    "text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f537a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #save cleaned df as pre_df\n",
    "\n",
    "# pre_df = df \n",
    "# pre_df.to_pickle('pre_df.pkl')\n",
    "# pre_df.to_csv(r'//Users/sandraparedes/Documents/GitHub/metis_dsml/05_nlp/g00-nlp-project/pre_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read df in\n",
    "# df = pd.read_csv('pre_df.csv', low_memory=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4fd41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaaahhhhhh</th>\n",
       "      <th>aaaaaand</th>\n",
       "      <th>aaaaah</th>\n",
       "      <th>aaaaand</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aaaannnd</th>\n",
       "      <th>...</th>\n",
       "      <th>ùöçùöäùö¢</th>\n",
       "      <th>ùöèùöõùöíùöéùöóùöçùöú</th>\n",
       "      <th>ùöëùöäùöôùöôùö¢</th>\n",
       "      <th>ùöëùöûùöñùöô</th>\n",
       "      <th>ùöíùöó</th>\n",
       "      <th>ùöíùöúùöó</th>\n",
       "      <th>ùöôùöéùöõùöúùöòùöó</th>\n",
       "      <th>ùöúùöíùöñùöôùöïùöé</th>\n",
       "      <th>ùöùùöëùöíùöú</th>\n",
       "      <th>ùö†ùöòùöõùöïùöç</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 164646 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaa  aaaa  aaaaaahhhhhh  aaaaaand  aaaaah  aaaaand  aaaah  aaaand  \\\n",
       "0   0    0     0             0         0       0        0      0       0   \n",
       "1   0    0     0             0         0       0        0      0       0   \n",
       "\n",
       "   aaaannnd  ...  ùöçùöäùö¢  ùöèùöõùöíùöéùöóùöçùöú  ùöëùöäùöôùöôùö¢  ùöëùöûùöñùöô  ùöíùöó  ùöíùöúùöó  ùöôùöéùöõùöúùöòùöó  ùöúùöíùöñùöôùöïùöé  ùöùùöëùöíùöú  \\\n",
       "0         0  ...    0        0      0     0   0    0       0       0     0   \n",
       "1         0  ...    0        0      0     0   0    0       0       0     0   \n",
       "\n",
       "   ùö†ùöòùöõùöïùöç  \n",
       "0      0  \n",
       "1      0  \n",
       "\n",
       "[2 rows x 164646 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first document-term matrix has default Count Vectorizer values - counts of unigrams\n",
    "cv1 = CountVectorizer(stop_words='english')\n",
    "\n",
    "text_cv1 = cv1.fit_transform(text)\n",
    "text_cv1 = cv1.transform(text)\n",
    "\n",
    "text_cv1_df = pd.DataFrame(text_cv1.toarray(), columns=cv1.get_feature_names_out())\n",
    "text_cv1_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a60f4",
   "metadata": {},
   "source": [
    "### 3 | [sentiment analysis](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g1-nlp-overview/nlp_unsupervised_nlp_exercises7.ipynb) code blocks<a id='3'></a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ed1a1",
   "metadata": {},
   "source": [
    "### 4 | [dim redux](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g2-dimensionality-reduction/nlp_unsupervised_dimensionality_reduction_exercises3.ipynb) and [PCA](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g2-dimensionality-reduction/PCA_digits.ipynb)<a id='4'></a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57bae2e",
   "metadata": {},
   "source": [
    "### 4 | [LSA + NMF](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g3-topic-modeling/Topic_Modeling_LSA_NMF.ipynb) [LSA chapter ex](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g3-topic-modeling/nlp_unsupervised_topic_modeling_exercises2.ipynb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa359cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe9913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f6341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4d583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (unsupervised)",
   "language": "python",
   "name": "unsupervised"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
