{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74975ac3",
   "metadata": {},
   "source": [
    "#### NLP | MVP\n",
    "\n",
    "# Coronavirus Tweets: Spring 2020<a id='top'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea017a0f",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "## **Analysis Goal**  \n",
    "The client, [name](link), ...\n",
    "wants to ... and \n",
    "requested a model to find a pattern ... in tweets in April. \n",
    "\n",
    "Impetus?\n",
    "\n",
    "**RQ:** ....?\n",
    "\n",
    "## **Process**\n",
    "**Data source:** \n",
    "Coronavirus COVID-19 Tweets [early](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-early-april) and [late](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-late-april) April\n",
    "\n",
    "\n",
    "**Models:** \n",
    "* [name] model, fit a [model name](#??):\n",
    "    * eval metric\n",
    "* [name] model, fit a [model name](#??):\n",
    "    * eval metric\n",
    "\n",
    "\n",
    "## **Preliminary Visualizations**\n",
    "[Figure 1. Name](#??)<br/>\n",
    "[Figure 1. Name](#??)<br/>\n",
    "\n",
    "## **Preliminary Conclusions**\n",
    "The [name] model ... showed....<br/>\n",
    "\n",
    "The next step .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64179b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob \n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38894c8",
   "metadata": {},
   "source": [
    "## 1 | Dataset: Coronavirus Tweets ([early](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-early-april) and [late](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-late-april) April) <a id='1'></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83cc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import one csv file to see data\n",
    "single_df = pd.read_csv('20200401.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the following 7 columns on full data import \n",
    "\n",
    " 2   created_at            591480 non-null  object \n",
    " 3   screen_name           591480 non-null  object \n",
    " 4   text                  591480 non-null  object \n",
    " 13  country_code          26040 non-null   object \n",
    " 18  account_lang          0 non-null       float64\n",
    " 20  verified              591480 non-null  bool   \n",
    " 21  lang                  591480 non-null  object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list of April 2020 files, while ommitting columns above\n",
    "\n",
    "path = r'/Users/sandraparedes/Documents/GitHub/metis_dsml/05_nlp/g00-nlp-project/data' \n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0, usecols=[2,3,4,13,18,20,21])\n",
    "    li.append(df)\n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678fce99",
   "metadata": {},
   "source": [
    "## 2 | Exploratory Data Analysis<a id='2'></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lang'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454cdc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('English entries:', (df[df[\"lang\"] == 'en'].count())['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('US entries:', (df[df[\"country_code\"] == 'US'].count())['country_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_us_df = df[(df['country_code'] == 'US') &\n",
    "               (df['lang'] == 'en')]\n",
    "eng_us_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d83d4",
   "metadata": {},
   "source": [
    "### English + US df: 138,789 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_us_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908cc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_us_df['text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b578af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9q/517kb3kd6rz7pq25y7fyk9w00000gn/T/ipykernel_16796/953567393.py:8: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('coronavirus_tweets_df.csv')\n"
     ]
    }
   ],
   "source": [
    "# #save cleaned df as tweet_df\n",
    "\n",
    "# tweet_df = eng_us_df \n",
    "# tweet_df.to_pickle('coronavirus_tweets_df.pkl')\n",
    "# tweet_df.to_csv(r'//Users/sandraparedes/Documents/GitHub/metis_dsml/05_nlp/g00-nlp-project/data/coronavirus_tweets_df.csv', index=False)\n",
    "\n",
    "#read df in\n",
    "df = pd.read_csv('coronavirus_tweets_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f2e931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceec71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4dc0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e34687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa359cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe9913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f6341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4d583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
