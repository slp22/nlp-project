{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74975ac3",
   "metadata": {},
   "source": [
    "#### NLP | MVP\n",
    "\n",
    "# Coronavirus Tweets: Spring 2020<a id='top'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea017a0f",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "## **Analysis Goal**  \n",
    "The client, [name](link), ...\n",
    "wants to ... and \n",
    "requested a model to find a pattern ... in tweets in April. \n",
    "\n",
    "Impetus?\n",
    "\n",
    "**RQ:** ....?\n",
    "\n",
    "## **Process**\n",
    "**Data source:** \n",
    "Coronavirus COVID-19 Tweets [early](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-early-april) and [late](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-late-april) April\n",
    "\n",
    "\n",
    "**Models:** \n",
    "* [name] model, fit a [model name](#??):\n",
    "    * eval metric\n",
    "* [name] model, fit a [model name](#??):\n",
    "    * eval metric\n",
    "\n",
    "\n",
    "## **Preliminary Visualizations**\n",
    "[Figure 1. Name](#??)<br/>\n",
    "[Figure 1. Name](#??)<br/>\n",
    "\n",
    "## **Preliminary Conclusions**\n",
    "The [name] model ... showed....<br/>\n",
    "\n",
    "The next step .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64179b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import string\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['retina']  # or svg\n",
    "sns.set(context='notebook', style='whitegrid')\n",
    "\n",
    "from itertools import cycle\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.util import ngrams\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "\n",
    "from cleantext import clean\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38894c8",
   "metadata": {},
   "source": [
    "## 1 | Dataset: Coronavirus Tweets ([early](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-early-april) and [late](https://www.kaggle.com/datasets/smid80/coronavirus-covid19-tweets-late-april) April) <a id='1'></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83cc9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import one csv file to see data\n",
    "# single_df = pd.read_csv('20200401.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the following 7 columns on full data import \n",
    "\n",
    "#  2   created_at            591480 non-null  object \n",
    "#  3   screen_name           591480 non-null  object \n",
    "#  4   text                  591480 non-null  object \n",
    "#  13  country_code          26040 non-null   object \n",
    "#  18  account_lang          0 non-null       float64\n",
    "#  20  verified              591480 non-null  bool   \n",
    "#  21  lang                  591480 non-null  object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read list of April 2020 files, while ommitting columns above\n",
    "\n",
    "# path = r'/Users/sandraparedes/Documents/GitHub/metis_dsml/05_nlp/g00-nlp-project/data' \n",
    "# all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# li = []\n",
    "\n",
    "# for filename in all_files:\n",
    "#     df = pd.read_csv(filename, index_col=None, header=0, usecols=[2,3,4,13,18,20,21])\n",
    "#     li.append(df)\n",
    "# df = pd.concat(li, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678fce99",
   "metadata": {},
   "source": [
    "## 2 | Exploratory Data Analysis<a id='2'></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['country_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['lang'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454cdc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('English entries:', (df[df[\"lang\"] == 'en'].count())['lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('US entries:', (df[df[\"country_code\"] == 'US'].count())['country_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eng_us_df = df[(df['country_code'] == 'US') &\n",
    "#                (df['lang'] == 'en')]\n",
    "# eng_us_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eng_us_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908cc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eng_us_df['text'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d83d4",
   "metadata": {},
   "source": [
    "### English + US df: 138,789 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b578af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save cleaned df as tweet_df\n",
    "\n",
    "# tweet_df = eng_us_df \n",
    "# tweet_df.to_pickle('coronavirus_tweets_df.pkl')\n",
    "# tweet_df.to_csv(r'//Users/sandraparedes/Documents/GitHub/metis_dsml/05_nlp/g00-nlp-project/data/coronavirus_tweets_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61163bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read df in\n",
    "df = pd.read_csv('coronavirus_tweets_df.csv', low_memory=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef27231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['created_at', 'screen_name', 'country_code', \n",
    "                 'account_lang', 'verified', 'lang'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233740c",
   "metadata": {},
   "source": [
    "### 2a | [start here with nlp](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g1-nlp-overview/NLP_Supervised_Learning.ipynb)<a id='2a'></a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bdb5a4",
   "metadata": {},
   "source": [
    "### Remove numbers, capital letters, and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*',' ', str(x))\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "                          \n",
    "df['text'] = df.text.map(alphanumeric).map(punc_lower)\n",
    "df.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35067b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove emojis\n",
    "df = df.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8038e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f537a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save clean df\n",
    "\n",
    "clean_covid_tweets_df = df \n",
    "clean_covid_tweets_df.to_pickle('clean_covid_tweets_df.pkl')\n",
    "clean_covid_tweets_df.to_csv(r'//Users/sandraparedes/Documents/GitHub/metis_dsml/05_nlp/g00-nlp-project/clean_covid_tweets_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read df in\n",
    "# df = pd.read_csv('clean_covid_tweets_df.csv', low_memory=False)\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4fd41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer values - counts of unigrams\n",
    "\n",
    "X = df.text\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "text_cv = cv.fit_transform(X)\n",
    "# text_cv1 = cv1.transform(X)\n",
    "\n",
    "text_df_cv = pd.DataFrame(text_cv.toarray(), columns=cv.get_feature_names_out())\n",
    "text_df_cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a60f4",
   "metadata": {},
   "source": [
    "### 3 | [sentiment analysis](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g1-nlp-overview/nlp_unsupervised_nlp_exercises7.ipynb) code blocks<a id='3'></a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f59c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer() \n",
    "sentiment = analyzer.polarity_scores(df).get('compound')\n",
    "print('compound', sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df.text.map(analyzer.polarity_scores).map(lambda x: x.get('compound'))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ed1a1",
   "metadata": {},
   "source": [
    "### 4 | [dim redux](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g2-dimensionality-reduction/nlp_unsupervised_dimensionality_reduction_exercises3.ipynb) and [PCA](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g2-dimensionality-reduction/PCA_digits.ipynb)<a id='4'></a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22abdcb",
   "metadata": {},
   "source": [
    "# bookmark Thurs evening\n",
    "# kernel quits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c24341",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_5 = PCA(n_components=5)\n",
    "pca_5.fit(text_df_cv)\n",
    "# pcafeatures = pca_5.transform(text_df_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_5_components = pca_5.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7e7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc5_positives = []\n",
    "pc5_positives.append(text_df_cv1.columns[4])\n",
    "pc5_positives.append(text_df_cv1.columns[5])\n",
    "pc5_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57bae2e",
   "metadata": {},
   "source": [
    "### 4 | [LSA + NMF](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g3-topic-modeling/Topic_Modeling_LSA_NMF.ipynb) [LSA chapter ex](http://localhost:8888/notebooks/Documents/GitHub/metis_dsml/05_nlp/g3-topic-modeling/nlp_unsupervised_topic_modeling_exercises2.ipynb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa359cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe9913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f6341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4d583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (unsupervised)",
   "language": "python",
   "name": "unsupervised"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
